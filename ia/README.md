# Intelligence artificielle

## Types d'IA

Le terme « IA », sans qualificatif, est un **buzzword** marketing qui embrouille le public. Ainsi, le terme « IA » devrait toujours être suivi d’un qualificatif pour préciser son type, car ces technologies sont très différentes.

Voici les types d’IA que l’on retrouve dans le discours public ambiant :

- **IA générative (GenAI/LLM)** : ChatGPT, Claude, Grok, etc.
- **IA générale (AGI)** : **hypothétique – n’existe pas**

---

### Comparatif

| **Critère**                                          | **IA générative (GenAI/LLM)**                                    | **IA générale (AGI)**                                                                                                   |
| ---------------------------------------------------- | ---------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------- |
| **Domaine d'application**                            | Large éventail de tâches dans plusieurs domaines                 | Tous domaines, avec adaptation contextuelle comme un humain                                                             |
| **Contrôle et gouvernance**                          | ❌ Moins contrôlable, comportements complexes et parfois imprévus | 🤔 Autonome, nécessiterait des formes avancées de régulation et d’éthique                                               |
| **Fiabilité et sécurité**                            | ❌ Risques de biais, d’erreurs ou de dérives                      | ❌❌ Risques amplifiés : imprévisibilité, potentiel d’action autonome                                                     |
| **Transparence**                                     | 🤔 Plus opaque, explicabilité partielle                          | 🤔 Potentiellement difficile à comprendre, voire ininterprétable                                                        |
| **Pertinence en contexte éducatif/public**           | 🤔 Utile, mais nécessite un encadrement                           | ❌ Hypothétique et potentiellement risquée sans garanties strictes                                                       |
| **Impact environnemental, énergétique et extractif** | ⛽️ Élevé : modèles massifs, infrastructure lourde                | 🌎💥 Très élevé (hypothétique) : besoin d’énormes ressources pour l'entraînement, l’autonomie et la simulation générale |
| **Durabilité**                                       | ❌ Moins durable, dépendance aux géants du cloud                  | ❌❌ Inconnue, mais probablement insoutenable dans sa forme actuelle                                                      |
| **Coûts**                                            | 💰💰💰 Très élevés : en données, calcul, maintenance             | 💰💰💰💰💰💰 Extrêmement élevés (hypothétiques), en R&D, énergie, gouvernance                                          |
| **État actuel**                                      | En usage courant (LLM, assistants IA)                            | Hypothétique, pas encore réalisée                                                                                       |

---

Il existe aussi un autre type d’IA, **l’IA spécifique bien délimitée**, qui est plus restreinte, mais aussi plus durable. Cela n’intéresse généralement pas les grandes entreprises, car elle n’est pas hégémonique.

| **Critère**                                          | **IA spécifique bien délimitée**             |
| ---------------------------------------------------- | -------------------------------------------- |
| **Domaine d'application**                            | Restreint, bien défini                       |
| **Contrôle et gouvernance**                          | Fortement encadrée par des règles explicites |
| **Fiabilité et sécurité**                            | Prévisible et testable                       |
| **Transparence**                                     | Explicable, logique traçable                 |
| **Pertinence en contexte éducatif/public**           | Idéale pour soutenir des objectifs ciblés    |
| **Impact environnemental, énergétique et extractif** | Faible à modéré                              |
| **Durabilité**                                       | Soutenable et adaptable localement           |
| **Coûts**                                            | Faibles à modérés                            |
| **État actuel**                                      | Déjà largement déployée                      |

---

> [!NOTE]
> Contrairement à ce que l’on pourrait croire, les technologies d’IA ne sont pas récentes. Elles sont en développement depuis près de 75 ans, avec des racines remontant aux premiers modèles symboliques des années 1950.

> [!WARNING]
> Contrairement à la confusion véhiculée par le marketing techno-solutionniste, une IA générative (GenAI/LLM) **ne peut pas évoluer** en IA générale (AGI). Ce sont deux technologies fondamentalement distinctes, tant par leur architecture que par leur fonctionnement.

## Questions critiques


### Sur l'enseignement

- **Utiliser ChatGPT pendant l'apprentissage pourrait nuire aux capacités de pensée critique**
  Une équipe de neurologues et spécialistes en IA du Media Lab du MIT a mené une étude sur l’impact des grands modèles de langage (LLM/GenAI), comme ChatGPT, sur le cerveau des utilisateurs lors de tâches d’écriture, un groupe utilisant ChatGPT, un autre utilisant Google Search, et un dernier sans aucun outil. Les résultats montrent que le groupe sans assitance présentait la plus forte activité cérébrale et engagement mental, le groupe Google était intermédiaire, et le groupe ChatGPT avait la connectivité cérébrale la plus faible. Après plusieurs mois, ceux qui avaient utilisé ChatGPT précédemment ont montré une activité cérébrale plus faible et une mémoire moins performante. Ils ressentaient moins de sentiment de propriété sur leurs essais et avaient plus de difficultés à s’en souvenir ou à les citer. [Using ChatGPT to write essays may be eroding critical thinking skills](https://phys.org/news/2025-06-chatgpt-essays-eroding-critical-skills.html)

- **La personne qui utilise ou « prompte » une GenAI doit avoir une solide expertise du métier.**  
  Même si l’outil accomplit certaines tâches à sa place, **tout doit être vérifié, validé, corrigé**. Sans cette compétence métier, l’IA générative devient un générateur d’erreurs crédibles mais dangereuses.

- **Allons-nous enseigner à nos étudiants des outils ou des techniques voués à disparaître dans trois ans ?**  
  La rapidité des cycles d’innovation et d’obsolescence impose une réflexion de fond sur **ce qu’il est réellement pertinent de transmettre** : des compétences techniques à court terme, ou des capacités critiques, créatives et adaptatives qui résisteront au temps ?

- **Les diplômés seront remplacés par une IA générale (AGI)?**  
  Si l’on adhère au discours technosolutionniste selon lequel les machines finiront par surpasser les humains, alors **pourquoi continuer à former des étudiants** ? Que devient le sens de l’éducation dans un monde où l’AGI est censée tout faire à notre place ?



### Précédents

- **Les promoteurs de l’IA en éducation sont les mêmes qui ont introduit les téléphones intelligents et les réseaux sociaux.**  
  Or, nous avons vu **les impacts négatifs de ces technologies sur les jeunes** — isolement, détresse mentale, distraction permanente. Et maintenant, on nous dit : *« Cette fois-ci, ce sera différent ? »*

- **L’IA est un outil puissant, mais pas une transformation systémique en soi.**  
  L’exagération actuelle autour de l’IA rappelle les discours précédents sur le **bitcoin**, la **blockchain**, ou la **réalité virtuelle**. Il faut rester critique : **toute technologie n’est pas une panacée**.

### Promesses

- **La vision de la Silicon Valley sur l’IA est-elle fondée ?**  
  On nous promet que l’IA guérira le cancer, mettra fin à la faim dans le monde, etc. — mais **il n’y a actuellement aucune preuve scientifique concrète** que ces affirmations soient réalisables.

- **Comment peut-on vouloir reproduire l’intelligence humaine alors même que la science ne s’entend pas sur ce qu’est l’intelligence humaine ?**  
  Il n’existe **aucun consensus scientifique clair** sur la nature de l’intelligence, de la conscience, ou de l’intention.

### Droit d'auteur

-  **Événement révélateur sur le droit d'auteur**
    Le 8 mai 2025, le président Trump a congédié **Carla Hayden**, bibliothécaire du Congrès, **un jour après** la publication par l’US Copyright Office d’un rapport préliminaire sur **les GenAI et le droit d’auteur**.  Ce rapport indiquait que l’entraînement des GenAI sur des œuvres protégées **ne relève probablement pas du fair use**, ce qui **remet en cause la légalité** de nombreuses pratiques actuelles.

### Quel futur nous propose-t-on vraiment ?

- **Un futur d’extractivisme numérique** :  
  - Disparition de la vie privée  
  - Surveillance accrue  
  - Précarité des emplois  
  - Productivité accrue sans gain salarial


- **Le sentiment d’inévitabilité est une construction narrative.**  
  Silicon Valley cultive l’idée que « le futur est déjà écrit ». Mais **l’histoire des empires technologiques montre que tous peuvent s’effondrer** : IBM, les États-Unis, Yahoo, Nokia… Et bien d’autres.

### Nous vivons présentement l'âge d'or de l'IA, sur le point de se terminer

- **Le coût d’utilisation des GenAI est aujourd’hui artificiellement bas.**  
  Leur accès est **fortement subventionné** par le capital-risque, ce qui donne l’illusion qu’ils sont peu coûteux, voire gratuits. Mais ces subventions sont en train de s’évaporer...
- Nous constatons le développement de  **Sycophant AI** : des GenAI conçues pour dire ce que l'utilisateur veut entendre, sans esprit critique.
  - [AI-Fueled Spiritual Delusions Are Destroying Human Relationships](https://www.rollingstone.com/culture/culture-features/ai-spiritual-delusions-destroying-human-relationships-1235330175/)
- Le **marketing** est au cœur du discours sur l’IA et prochainement de ses produits :  
  - **Kate Rouch**, ancienne de Meta, est aujourd’hui la première directrice du marketing d’OpenAI.
- Les erreurs abondent :
  - CamoGPT, une GenAI développée par l’armée américaine, a récemment été utilisée pour supprimer automatiquement des contenus jugés non conformes à de nouvelles directives politiques. Cette opération a mené à des erreurs notables, comme la suppression d’archives historiques liées au bombardier Enola Gay, simplement à cause de son nom contenant le mot "Gay". L’IA a également écarté d’autres documents importants liés à des figures militaires historiques, révélant les limites graves de ces systèmes lorsqu’ils manquent de compréhension contextuelle. Ces incidents soulignent l’importance d’une supervision humaine dans les usages sensibles de l’IA.
  - [Therapy Chatbot Tells Recovering Addict to Have a Little Meth as a Treat](https://futurism.com/therapy-chatbot-addict-meth)
- Les manipulations abondent :  
  - L’IA **Grok**, développée par xAI (Elon Musk), a été accusée de **diffuser de fausses informations**, comme la théorie du « génocide blanc » en Afrique du Sud.
- **Atteinte du plafond du développement des GenAI**
  Le développement de l’IA générative a progressé à un rythme effréné, mais il pourrait exister une limite mathématique infranchissable — un plafond — qui marquerait la fin de son évolution fulgurante.
  Beaucoup misent sur l’idée de rendre l’IA générative toujours plus intelligente — mais que se passe-t-il si les données nécessaires à son développement n’existent tout simplement plus ? [AI Has a Fatal Flaw—And Nobody Can Fix It - YouTube](https://www.youtube.com/watch?v=_IOh0S_L3C4)
- Le 15 août 2025, Sam Altman (PDG d’OpenAI) a reconnu que nous traversons actuellement une bulle autour de l’IA — un engouement exagéré, mais fondé sur un noyau de réalité — tout en affirmant qu’il compte bien en tirer parti, notamment en investissant des **billions** de dollars dans de nouveaux centres de données pour rester aux commandes après l’éclatement.  
[Lire l’article original (The Register, 15 août 2025)](https://www.theregister.com/2025/08/15/boy_riding_bubble_realizes_what/)


### Perfomances d'un GenAI 

Un GML, c’est un très bon imitateur qui peut parler comme un philosophe, un ingénieur ou un poète — mais qui ne comprend pas vraiment ce qu’il dit.  On y projette  des intentions ou des capacités qu’il n’a pas.

#### Complétences humaines vs machines

| **Compétences**                                           | **Humains** | **Machines** |
|-----------------------------------------------------------|-------------|-----------------|
| Opérations mathématiques                                  |             | ✅              |
| Mémoire et rappel                                         |             | ✅              |
| Raisonnement général (tests de QI)                        |             | ✅              |
| Prise de décision (scénarios de type jeu)                 |             | ✅              |
| Programmation de base                                     |             | ✅              |
| Bon sens                                                  | ✅          |                 |
| Créativité                                                | ✅          |                 |
| Prise de décision (dans le monde réel)                    | ✅          |                 |
| Mathématiques (résolution de problèmes complexes/créatifs)| ✅          |                 |


#### Capacité d'un GenAI pour jouer à un jeu

| Type de jeu                               | Performance d’un LLM | Remarques                                                               |
| ----------------------------------------- | ------------------------- | ----------------------------------------------------------------------- |
| **Échecs, Go, Shōgi**                     | ❌ Faible                  | Suit mal l’état du jeu, oublie les règles ou fait des coups illégaux    |
| **Morpion (Tic-Tac-Toe)**                 | ✅ Bonne                   | Jeu simple, facile à suivre en texte                                    |
| **Énigmes logiques**                      | 🤷 Moyenne                | Raisonnement souvent instable ou incohérent                             |
| **Jeux de stratégie (Catan, Risk, etc.)** | 🤔 Inconstante            | Peut simuler des dialogues ou des choix, mais sans planification réelle |
| **Jeux avec grille (Connect Four, etc.)** | 😬 Limite                 | Possible sur quelques tours, mais perd le fil rapidement                |

#### Limites d'un GenAI à extrapoler

![Dans cette séquence, il est clair que l'IA générative n'arrive pas à générer un verre de vin à rabord](./verre_de_vin.svg)





## Le monde devient plus idiot

La majeure partie de cette section est tirée de [AI Is Making You Dumber - YouTube](https://www.youtube.com/watch?v=G-cdVurdoeA).

![Declin de la performance de tests sur le raisonnement et la solution de problèmes](./decline_reasoning_problem_solving.png)

### Témoignages d'étudiants

Voici des témoignages d'étudiants recueillis par [The Chronicle of Higher Education | Higher Ed News, Opinion, & Advice](https://www.chronicle.com/) :
- « J’ai l’impression de trop dépendre de l’IA, et que ça m’a enlevé ma créativité. »
- « Je suis devenu plus paresseux. L’IA rend la lecture plus facile, mais elle fait lentement perdre à mon cerveau la capacité de penser de manière critique ou de comprendre chaque mot. »
- « C’est utile, mais j’ai peur qu’un jour, on préfère lire uniquement des résumés générés par l’IA plutôt que les nôtres, et qu’on devienne très dépendants de l’IA. »

Lorsqu'elle est utilisée dans un contexte académique, l'IA générative est comme une dépendance, qui réduit graduellement notre capacité intelectuelle.

### Recherches corporatives

- « Microsoft Research a découvert que plus les gens avaient confiance en l’IA, moins ils faisaient preuve de pensée critique lorsqu’ils l’utilisaient. »
- « Une étude menée par Anthropic, qui développe le programme d’IA Claude, a révélé que les étudiants l’utilisaient pour déléguer les tâches de réflexion difficile. L’étude ajoute qu’il existe des inquiétudes légitimes : les systèmes d’IA pourraient devenir une béquille pour les étudiants, freinant le développement des compétences fondamentales nécessaires à une pensée de plus haut niveau. »

Les entreprises qui développent l’IA — ce produit qu’elles affirment pouvoir révolutionner positivement la société humaine — nous disent aussi que leur produit est littéralement en train de nous rendre plus bêtes.
C’est comme si les fabricants de cigarettes découvraient qu’elles provoquent le cancer, mais disaient ensuite : « Non non, le cancer est une fonctionnalité. Le cancer arrive, et il va falloir s’adapter. »
Cela va aussi éliminer beaucoup d’emplois… ainsi que ceux qui les occupent.

## Comment avoir un avantage compétif en tant que futur diplômé

- 💡 **Le piège des GenAI** : 
  - Utiliser ChatGPT ou toute autre GenAI pour remplacer ta propre réflexion dans un contexte éducatif affaiblit réellement tes capacités cognitives.
  - Ton intellect devient plus faible et moins performant.

- 🧠 **Renforcer son cerveau : mental de métal** : 
  - Les étudiants qui ont réalisé leurs travaux avec leur cerveau obtiennent *à long terme* de meilleurs résultats.
  - Et surtout, leur intellect ne régresse pas en utilisant une GenAI plus tard.
  - Refuser de laisser l’IA générative penser à ta place te rend plus résistant aux effets d’affaiblissement cognitif liés à l’IA générative.

- ✊  **Un conseil simple aux étudiants** 
  - Tu veux dépasser tous ceux qui utilisent l'IA générative pour faire leurs travaux, surtout quand vous serez sur le marché du travail (pour faire plus d'argent 🤑) ?
  - Alors n’utilise pas de GenAI pour faire tes travaux!

- 🏋️ **Oui, ce sera dur... comme aller à la salle de sport...**
  - Tu devras écrire toi-même.
  - Tu te sentiras peut-être bête.
  - Tu galéreras avec des problèmes.
  - Ce sera long, agaçant et pénible sur le moment,
  - mais tu t’en porteras mieux toute ta vie.

- 🏆 **...Mais tu seras meilleur que tous les autres**
  - Tu deviendras plus résistant intellectuellement et auras développé de meilleures facultés cognitives.
  - Tu seras donc plus capable que ceux qui t’entourent — pour le reste de ta vie.


![](./mental_de_meta3l.png)